{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DRLND.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SankalpA11/DRL/blob/master/DRLND.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8KxmtQajxEn",
        "colab_type": "text"
      },
      "source": [
        "#Deep reinforcement learning\n",
        "**Tic tac toe game**\n",
        "*Part1, chapter 1, RL Text book*\n",
        "This below code is to make a tic tac toe game and make two agents play against each other.\n",
        "This code has been taken from the below stated source.\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "Copyright (C)                                                       \n",
        " 2016 - 2018 Shangtong Zhang(zhangshangtong.cpp@gmail.com)           \n",
        " 2016 Jan Hakenberg(jan.hakenberg@gmail.com)                         \n",
        " 2016 Tian Jun(tianjun.cpp@gmail.com)                                \n",
        " 2016 Kenta Shimada(hyperkentakun@gmail.com)                         \n",
        " Permission given to modify the code as long as you keep this        \n",
        " declaration at the top                                              \n",
        "#######################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LIJ1_rplCpF",
        "colab_type": "text"
      },
      "source": [
        "**Importing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr7N0Eq5i6eY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1ccPBWclSaP",
        "colab_type": "text"
      },
      "source": [
        "Initialize the variables : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbjiU5QPlQOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOARD_ROWS = 3\n",
        "BOARD_COLS = 3\n",
        "BOARD_SIZE = BOARD_ROWS * BOARD_COLS\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n98ypDHrmAdf",
        "colab_type": "text"
      },
      "source": [
        "Declear a class called *State* which will make the environment and generate the states for the agent to be in.\n",
        "This states will help the agents to work in and play accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0VntdFqlayg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class State:\n",
        "    def __init__(self):\n",
        "        # the board is represented by an n * n array,\n",
        "        # 1 represents a chessman of the player who moves first,\n",
        "        # -1 represents a chessman of another player\n",
        "        # 0 represents an empty position\n",
        "        self.data = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.winner = None\n",
        "        self.hash_val = None\n",
        "        self.end = None\n",
        "\n",
        "    # compute the hash value for one state, it's unique\n",
        "    def hash(self):\n",
        "        if self.hash_val is None:\n",
        "            self.hash_val = 0\n",
        "            for i in np.nditer(self.data):\n",
        "                self.hash_val = self.hash_val * 3 + i + 1\n",
        "        return self.hash_val\n",
        "\n",
        "    # check whether a player has won the game, or it's a tie\n",
        "    def is_end(self):\n",
        "        if self.end is not None:\n",
        "            return self.end\n",
        "        results = []\n",
        "        # check row\n",
        "        for i in range(BOARD_ROWS):\n",
        "            results.append(np.sum(self.data[i, :]))\n",
        "        # check columns\n",
        "        for i in range(BOARD_COLS):\n",
        "            results.append(np.sum(self.data[:, i]))\n",
        "\n",
        "        # check diagonals\n",
        "        trace = 0\n",
        "        reverse_trace = 0\n",
        "        for i in range(BOARD_ROWS):\n",
        "            trace += self.data[i, i]\n",
        "            reverse_trace += self.data[i, BOARD_ROWS - 1 - i]\n",
        "        results.append(trace)\n",
        "        results.append(reverse_trace)\n",
        "\n",
        "        for result in results:\n",
        "            if result == 3:\n",
        "                self.winner = 1\n",
        "                self.end = True\n",
        "                return self.end\n",
        "            if result == -3:\n",
        "                self.winner = -1\n",
        "                self.end = True\n",
        "                return self.end\n",
        "\n",
        "        # whether it's a tie\n",
        "        sum_values = np.sum(np.abs(self.data))\n",
        "        if sum_values == BOARD_SIZE:\n",
        "            self.winner = 0\n",
        "            self.end = True\n",
        "            return self.end\n",
        "\n",
        "        # game is still going on\n",
        "        self.end = False\n",
        "        return self.end\n",
        "\n",
        "    # @symbol: 1 or -1\n",
        "    # put chessman symbol in position (i, j)\n",
        "    def next_state(self, i, j, symbol):\n",
        "        new_state = State()\n",
        "        new_state.data = np.copy(self.data)\n",
        "        new_state.data[i, j] = symbol\n",
        "        return new_state\n",
        "\n",
        "    # print the board\n",
        "    def print_state(self):\n",
        "        for i in range(BOARD_ROWS):\n",
        "            print('-------------')\n",
        "            out = '| '\n",
        "            for j in range(BOARD_COLS):\n",
        "                if self.data[i, j] == 1:\n",
        "                    token = '*'\n",
        "                elif self.data[i, j] == -1:\n",
        "                    token = 'x'\n",
        "                else:\n",
        "                    token = '0'\n",
        "                out += token + ' | '\n",
        "            print(out)\n",
        "        print('-------------')\n",
        "\n",
        "\n",
        "def get_all_states_impl(current_state, current_symbol, all_states):\n",
        "    for i in range(BOARD_ROWS):\n",
        "        for j in range(BOARD_COLS):\n",
        "            if current_state.data[i][j] == 0:\n",
        "                new_state = current_state.next_state(i, j, current_symbol)\n",
        "                new_hash = new_state.hash()\n",
        "                if new_hash not in all_states:\n",
        "                    is_end = new_state.is_end()\n",
        "                    all_states[new_hash] = (new_state, is_end)\n",
        "                    if not is_end:\n",
        "                        get_all_states_impl(new_state, -current_symbol, all_states)\n",
        "\n",
        "\n",
        "def get_all_states():\n",
        "    current_symbol = 1\n",
        "    current_state = State()\n",
        "    all_states = dict()\n",
        "    all_states[current_state.hash()] = (current_state, current_state.is_end())\n",
        "    get_all_states_impl(current_state, current_symbol, all_states)\n",
        "    return all_states\n",
        "\n",
        "\n",
        "# all possible board configurations\n",
        "all_states = get_all_states()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBmM80C_lief",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Judger:\n",
        "    # @player1: the player who will move first, its chessman will be 1\n",
        "    # @player2: another player with a chessman -1\n",
        "    def __init__(self, player1, player2):\n",
        "        self.p1 = player1\n",
        "        self.p2 = player2\n",
        "        self.current_player = None\n",
        "        self.p1_symbol = 1\n",
        "        self.p2_symbol = -1\n",
        "        self.p1.set_symbol(self.p1_symbol)\n",
        "        self.p2.set_symbol(self.p2_symbol)\n",
        "        self.current_state = State()\n",
        "\n",
        "    def reset(self):\n",
        "        self.p1.reset()\n",
        "        self.p2.reset()\n",
        "\n",
        "    def alternate(self):\n",
        "        while True:\n",
        "            yield self.p1\n",
        "            yield self.p2\n",
        "\n",
        "    # @print_state: if True, print each board during the game\n",
        "    def play(self, print_state=False):\n",
        "        alternator = self.alternate()\n",
        "        self.reset()\n",
        "        current_state = State()\n",
        "        self.p1.set_state(current_state)\n",
        "        self.p2.set_state(current_state)\n",
        "        if print_state:\n",
        "            current_state.print_state()\n",
        "        while True:\n",
        "            player = next(alternator)\n",
        "            i, j, symbol = player.act()\n",
        "            next_state_hash = current_state.next_state(i, j, symbol).hash()\n",
        "            current_state, is_end = all_states[next_state_hash]\n",
        "            self.p1.set_state(current_state)\n",
        "            self.p2.set_state(current_state)\n",
        "            if print_state:\n",
        "                current_state.print_state()\n",
        "            if is_end:\n",
        "                return current_state.winner\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeh73R3vlwO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AI player\n",
        "class Player:\n",
        "    # @step_size: the step size to update estimations\n",
        "    # @epsilon: the probability to explore\n",
        "    def __init__(self, step_size=0.1, epsilon=0.1):\n",
        "        self.estimations = dict()\n",
        "        self.step_size = step_size\n",
        "        self.epsilon = epsilon\n",
        "        self.states = []\n",
        "        self.greedy = []\n",
        "        self.symbol = 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.states = []\n",
        "        self.greedy = []\n",
        "\n",
        "    def set_state(self, state):\n",
        "        self.states.append(state)\n",
        "        self.greedy.append(True)\n",
        "\n",
        "    def set_symbol(self, symbol):\n",
        "        self.symbol = symbol\n",
        "        for hash_val in all_states:\n",
        "            state, is_end = all_states[hash_val]\n",
        "            if is_end:\n",
        "                if state.winner == self.symbol:\n",
        "                    self.estimations[hash_val] = 1.0\n",
        "                elif state.winner == 0:\n",
        "                    # we need to distinguish between a tie and a lose\n",
        "                    self.estimations[hash_val] = 0.5\n",
        "                else:\n",
        "                    self.estimations[hash_val] = 0\n",
        "            else:\n",
        "                self.estimations[hash_val] = 0.5\n",
        "\n",
        "    # update value estimation\n",
        "    def backup(self):\n",
        "        states = [state.hash() for state in self.states]\n",
        "\n",
        "        for i in reversed(range(len(states) - 1)):\n",
        "            state = states[i]\n",
        "            td_error = self.greedy[i] * (\n",
        "                self.estimations[states[i + 1]] - self.estimations[state]\n",
        "            )\n",
        "            self.estimations[state] += self.step_size * td_error\n",
        "\n",
        "    # choose an action based on the state\n",
        "    def act(self):\n",
        "        state = self.states[-1]\n",
        "        next_states = []\n",
        "        next_positions = []\n",
        "        for i in range(BOARD_ROWS):\n",
        "            for j in range(BOARD_COLS):\n",
        "                if state.data[i, j] == 0:\n",
        "                    next_positions.append([i, j])\n",
        "                    next_states.append(state.next_state(\n",
        "                        i, j, self.symbol).hash())\n",
        "\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            action = next_positions[np.random.randint(len(next_positions))]\n",
        "            action.append(self.symbol)\n",
        "            self.greedy[-1] = False\n",
        "            return action\n",
        "\n",
        "        values = []\n",
        "        for hash_val, pos in zip(next_states, next_positions):\n",
        "            values.append((self.estimations[hash_val], pos))\n",
        "        # to select one of the actions of equal value at random due to Python's sort is stable\n",
        "        np.random.shuffle(values)\n",
        "        values.sort(key=lambda x: x[0], reverse=True)\n",
        "        action = values[0][1]\n",
        "        action.append(self.symbol)\n",
        "        return action\n",
        "\n",
        "    def save_policy(self):\n",
        "        with open('policy_%s.bin' % ('first' if self.symbol == 1 else 'second'), 'wb') as f:\n",
        "            pickle.dump(self.estimations, f)\n",
        "\n",
        "    def load_policy(self):\n",
        "        with open('policy_%s.bin' % ('first' if self.symbol == 1 else 'second'), 'rb') as f:\n",
        "            self.estimations = pickle.load(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlsF4MNmlxde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# human interface\n",
        "# input a number to put a chessman\n",
        "# | q | w | e |\n",
        "# | a | s | d |\n",
        "# | z | x | c |\n",
        "class HumanPlayer:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.symbol = None\n",
        "        self.keys = ['q', 'w', 'e', 'a', 's', 'd', 'z', 'x', 'c']\n",
        "        self.state = None\n",
        "\n",
        "    def reset(self):\n",
        "        pass\n",
        "\n",
        "    def set_state(self, state):\n",
        "        self.state = state\n",
        "\n",
        "    def set_symbol(self, symbol):\n",
        "        self.symbol = symbol\n",
        "\n",
        "    def act(self):\n",
        "        self.state.print_state()\n",
        "        key = input(\"Input your position:\")\n",
        "        data = self.keys.index(key)\n",
        "        i = data // BOARD_COLS\n",
        "        j = data % BOARD_COLS\n",
        "        return i, j, self.symbol\n",
        "\n",
        "\n",
        "def train(epochs, print_every_n=500):\n",
        "    player1 = Player(epsilon=0.01)\n",
        "    player2 = Player(epsilon=0.01)\n",
        "    judger = Judger(player1, player2)\n",
        "    player1_win = 0.0\n",
        "    player2_win = 0.0\n",
        "    for i in range(1, epochs + 1):\n",
        "        winner = judger.play(print_state=False)\n",
        "        if winner == 1:\n",
        "            player1_win += 1\n",
        "        if winner == -1:\n",
        "            player2_win += 1\n",
        "        if i % print_every_n == 0:\n",
        "            print('Epoch %d, player 1 winrate: %.02f, player 2 winrate: %.02f' % (i, player1_win / i, player2_win / i))\n",
        "        player1.backup()\n",
        "        player2.backup()\n",
        "        judger.reset()\n",
        "    player1.save_policy()\n",
        "    player2.save_policy()\n",
        "\n",
        "\n",
        "def compete(turns):\n",
        "    player1 = Player(epsilon=0)\n",
        "    player2 = Player(epsilon=0)\n",
        "    judger = Judger(player1, player2)\n",
        "    player1.load_policy()\n",
        "    player2.load_policy()\n",
        "    player1_win = 0.0\n",
        "    player2_win = 0.0\n",
        "    for _ in range(turns):\n",
        "        winner = judger.play()\n",
        "        if winner == 1:\n",
        "            player1_win += 1\n",
        "        if winner == -1:\n",
        "            player2_win += 1\n",
        "        judger.reset()\n",
        "    print('%d turns, player 1 win %.02f, player 2 win %.02f' % (turns, player1_win / turns, player2_win / turns))\n",
        "\n",
        "\n",
        "# The game is a zero sum game. If both players are playing with an optimal strategy, every game will end in a tie.\n",
        "# So we test whether the AI can guarantee at least a tie if it goes second.\n",
        "def play():\n",
        "    while True:\n",
        "        player1 = HumanPlayer()\n",
        "        player2 = Player(epsilon=0)\n",
        "        judger = Judger(player1, player2)\n",
        "        player2.load_policy()\n",
        "        winner = judger.play()\n",
        "        if winner == player2.symbol:\n",
        "            print(\"You lose!\")\n",
        "        elif winner == player1.symbol:\n",
        "            print(\"You win!\")\n",
        "        else:\n",
        "            print(\"It is a tie!\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train(int(1e5))\n",
        "    compete(int(1e3))\n",
        "    play()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}